#!/usr/bin/env python3
"""
Script ƒë·ªÉ ph√¢n t√≠ch c·∫•u tr√∫c HTML v√† t√¨m selector ch√≠nh x√°c cho n·ªôi dung b√†i vi·∫øt
"""

import os
from bs4 import BeautifulSoup
import re

def analyze_html_structure(html_file):
    """Ph√¢n t√≠ch c·∫•u tr√∫c HTML ƒë·ªÉ t√¨m selector ch√≠nh x√°c"""
    
    print(f"üîç Ph√¢n t√≠ch file: {html_file}")
    print("=" * 60)
    
    with open(html_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    soup = BeautifulSoup(content, 'html.parser')
    
    # T√¨m c√°c selector c√≥ th·ªÉ ch·ª©a n·ªôi dung b√†i vi·∫øt
    content_selectors = [
        '.content-detail',
        '.article-content', 
        '.content',
        '.detail-content',
        '.article-body',
        '.post-content',
        '.entry-content',
        '.main-content',
        '.story-content',
        '.article-detail',
        '.news-content',
        '.story-body',
        '.article-text',
        '.news-text'
    ]
    
    print("üìã K·∫øt qu·∫£ ph√¢n t√≠ch c√°c selector:")
    print("-" * 40)
    
    for selector in content_selectors:
        elements = soup.select(selector)
        if elements:
            element = elements[0]
            # ƒê·∫øm s·ªë ·∫£nh trong element n√†y
            images = element.find_all('img')
            # ƒê·∫øm s·ªë ƒëo·∫°n vƒÉn
            paragraphs = element.find_all('p')
            # L·∫•y text m·∫´u
            text_sample = element.get_text()[:100].strip()
            
            print(f"‚úÖ {selector}:")
            print(f"   - S·ªë ·∫£nh: {len(images)}")
            print(f"   - S·ªë ƒëo·∫°n vƒÉn: {len(paragraphs)}")
            print(f"   - Text m·∫´u: {text_sample}...")
            
            # Hi·ªÉn th·ªã m·ªôt s·ªë ·∫£nh ƒë·∫ßu ti√™n
            if images:
                print(f"   - ·∫¢nh ƒë·∫ßu ti√™n:")
                for i, img in enumerate(images[:3]):
                    src = img.get('src', '')
                    alt = img.get('alt', '')
                    print(f"     {i+1}. src: {src[:80]}...")
                    print(f"        alt: {alt[:50]}...")
            print()
    
    # T√¨m t·∫•t c·∫£ ·∫£nh trong trang v√† ph√¢n lo·∫°i
    print("üñºÔ∏è  Ph√¢n t√≠ch t·∫•t c·∫£ ·∫£nh trong trang:")
    print("-" * 40)
    
    all_images = soup.find_all('img')
    print(f"T·ªïng s·ªë ·∫£nh: {len(all_images)}")
    
    # Ph√¢n lo·∫°i ·∫£nh theo URL
    content_images = []
    sidebar_images = []
    ad_images = []
    
    for img in all_images:
        src = img.get('src', '')
        alt = img.get('alt', '')
        
        # Ki·ªÉm tra xem ·∫£nh c√≥ ph·∫£i l√† ·∫£nh n·ªôi dung kh√¥ng
        if any(keyword in src.lower() for keyword in ['cdnmedia', 'cdnthumb']):
            if any(keyword in alt.lower() for keyword in ['ch√∫ th√≠ch', '·∫£nh', 'h√¨nh']):
                content_images.append((src, alt))
            else:
                content_images.append((src, alt))
        elif any(keyword in src.lower() for keyword in ['banner', 'quang-cao', 'advertisement']):
            ad_images.append((src, alt))
        else:
            sidebar_images.append((src, alt))
    
    print(f"·∫¢nh n·ªôi dung: {len(content_images)}")
    print(f"·∫¢nh qu·∫£ng c√°o: {len(ad_images)}")
    print(f"·∫¢nh sidebar: {len(sidebar_images)}")
    
    # Hi·ªÉn th·ªã m·ªôt s·ªë ·∫£nh n·ªôi dung
    if content_images:
        print("\nüì∏ ·∫¢nh n·ªôi dung (10 ·∫£nh ƒë·∫ßu):")
        for i, (src, alt) in enumerate(content_images[:10]):
            print(f"{i+1}. {src[:80]}...")
            print(f"   Alt: {alt[:50]}...")
    
    # T√¨m c√°c div c√≥ class ch·ª©a t·ª´ kh√≥a li√™n quan ƒë·∫øn n·ªôi dung
    print("\nüîç T√¨m c√°c div c√≥ class li√™n quan ƒë·∫øn n·ªôi dung:")
    print("-" * 40)
    
    content_divs = soup.find_all('div', class_=re.compile(r'content|article|story|news|detail|body|text', re.I))
    
    for div in content_divs[:5]:  # Ch·ªâ xem 5 div ƒë·∫ßu
        class_name = ' '.join(div.get('class', []))
        images_count = len(div.find_all('img'))
        text_length = len(div.get_text())
        
        print(f"Div class: {class_name}")
        print(f"  - S·ªë ·∫£nh: {images_count}")
        print(f"  - ƒê·ªô d√†i text: {text_length}")
        print()

def main():
    # S·ª≠ d·ª•ng file debug_full_page.html c√≥ s·∫µn
    html_file = 'debug_full_page.html'
    
    if not os.path.exists(html_file):
        print("‚ùå Kh√¥ng t√¨m th·∫•y file debug_full_page.html")
        return
    
    analyze_html_structure(html_file)

if __name__ == "__main__":
    main() 