#!/usr/bin/env python3
"""
Script ƒë·ªÉ test c·∫•u tr√∫c HTML c·ªßa trang baotintuc.vn
"""

import requests
from bs4 import BeautifulSoup
import json
import urllib3
import ssl

# T·∫Øt c·∫£nh b√°o SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# T·∫°o SSL context t√πy ch·ªânh
ssl_context = ssl.create_default_context()
ssl_context.check_hostname = False
ssl_context.verify_mode = ssl.CERT_NONE

def test_page_structure():
    """Test c·∫•u tr√∫c HTML c·ªßa trang ph√°p lu·∫≠t"""
    
    # Th·ª≠ c·∫£ HTTP v√† HTTPS
    urls_to_try = [
        "http://baotintuc.vn/phap-luat-475ct0.htm",
        "https://baotintuc.vn/phap-luat-475ct0.htm"
    ]
    
    for url in urls_to_try:
        print(f"üîÑ Th·ª≠ URL: {url}")
        if test_single_url(url):
            break
    else:
        print("‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi b·∫•t k·ª≥ URL n√†o")

def test_single_url(url):
    """Test m·ªôt URL c·ª• th·ªÉ"""
    
    print("=" * 60)
    print("TEST C·∫§U TR√öC HTML - BAOTINTUC.VN")
    print("=" * 60)
    print(f"URL: {url}")
    print()
    
    try:
        # Headers ƒë·ªÉ gi·∫£ l·∫≠p browser
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'vi,en;q=0.8',
        }
        
        # G·ª≠i request
        print("üì° ƒêang g·ª≠i request...")
        session = requests.Session()
        session.verify = False
        response = session.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        print(f"‚úÖ Status code: {response.status_code}")
        print(f"üìÑ Content length: {len(response.text)} bytes")
        print()
        
        # Parse HTML
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # T√¨m c√°c selector c√≥ th·ªÉ ch·ª©a b√†i vi·∫øt
        selectors_to_test = [
            'div.list-news article',
            'div.list-news .item-news',
            '.list-news .item',
            '.news-list .item',
            'article',
            '.item-news',
            '.news-item',
            '.article-item'
        ]
        
        print("üîç T√¨m ki·∫øm b√†i vi·∫øt v·ªõi c√°c selector:")
        for selector in selectors_to_test:
            elements = soup.select(selector)
            print(f"   {selector}: {len(elements)} elements")
        
        print()
        
        # Test l·∫•y link b√†i vi·∫øt
        print("üîó Test l·∫•y link b√†i vi·∫øt:")
        link_selectors = [
            'a[href*="/phap-luat/"]',
            'article a',
            '.item-news a',
            '.news-item a'
        ]
        
        for selector in link_selectors:
            links = soup.select(selector)
            print(f"   {selector}: {len(links)} links")
            if links:
                for i, link in enumerate(links[:3]):  # Ch·ªâ hi·ªÉn th·ªã 3 link ƒë·∫ßu
                    href = link.get('href')
                    text = link.get_text(strip=True)[:50]
                    print(f"     {i+1}. {href} - {text}...")
        
        print()
        
        # Test l·∫•y title
        print("üìù Test l·∫•y title:")
        title_selectors = [
            'h3 a',
            'h2 a',
            '.title a',
            'a'
        ]
        
        for selector in title_selectors:
            titles = soup.select(selector)
            print(f"   {selector}: {len(titles)} titles")
            if titles:
                for i, title in enumerate(titles[:3]):
                    text = title.get_text(strip=True)[:50]
                    print(f"     {i+1}. {text}...")
        
        print()
        
        # Test l·∫•y ng√†y th√°ng
        print("üìÖ Test l·∫•y ng√†y th√°ng:")
        date_selectors = [
            '.time',
            '.date',
            '.datetime',
            'time',
            '.news-time'
        ]
        
        for selector in date_selectors:
            dates = soup.select(selector)
            print(f"   {selector}: {len(dates)} dates")
            if dates:
                for i, date in enumerate(dates[:3]):
                    text = date.get_text(strip=True)
                    print(f"     {i+1}. {text}")
        
        print()
        
        # L∆∞u HTML ƒë·ªÉ debug
        with open('debug_page.html', 'w', encoding='utf-8') as f:
            f.write(response.text)
        print("üíæ ƒê√£ l∆∞u HTML v√†o file debug_page.html")
        
        return True
        
    except requests.RequestException as e:
        print(f"‚ùå L·ªói request: {e}")
        return False
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        return False
    
    print("=" * 60)
    return True

if __name__ == "__main__":
    test_page_structure() 